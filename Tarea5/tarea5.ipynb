{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-29T22:59:08.478107500Z",
     "start_time": "2024-01-29T22:59:08.303210Z"
    }
   },
   "source": [
    "#Importamos\n",
    "# Importamos la función `make_classification` de la biblioteca `sklearn.datasets`.\n",
    "# Esta función genera conjuntos de datos de muestra para tareas de clasificación.\n",
    "# Es útil para probar y experimentar con modelos de aprendizaje automático.\n",
    "# Genera conjuntos de datos con propiedades especificadas como el número de muestras, características, clases y relaciones entre características y clases.\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Importamos la clase `LogisticRegression` de la biblioteca `sklearn.linear_model`.\n",
    "# Esta clase implementa la regresión logística, un algoritmo de clasificación común.\n",
    "# Se utiliza para modelar la probabilidad de un resultado binario (por ejemplo, 0 o 1).\n",
    "# Se entrena en datos etiquetados para aprender la relación entre las características y la variable objetivo.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importamos la función `train_test_split` de la biblioteca `sklearn.model_selection`.\n",
    "# Esta función divide un conjunto de datos en conjuntos de entrenamiento y prueba.\n",
    "# Es crucial para evaluar el rendimiento del modelo en datos no vistos.\n",
    "# Asegura la generalización y evita el sobreajuste.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importamos las funciones `roc_curve` y `roc_auc_score` de la biblioteca `sklearn.metrics`.\n",
    "# Estas funciones se utilizan para evaluar el rendimiento del modelo en tareas de clasificación.\n",
    "# `roc_curve` calcula la curva ROC (Receiver Operating Characteristic).\n",
    "# Es una visualización de la capacidad del modelo para distinguir entre clases.\n",
    "# Representa la tasa de verdaderos positivos (TPR) frente a la tasa de falsos positivos (FPR) en diferentes umbrales.\n",
    "# `roc_auc_score` calcula el AUC (Area Under the ROC Curve).\n",
    "# Es una medida numérica del rendimiento del modelo (un AUC más alto es mejor).\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Importamos el módulo `pyplot` de la biblioteca `matplotlib`.\n",
    "# Este módulo se utiliza para crear visualizaciones como gráficos y diagramas.\n",
    "# En este código, probablemente se utiliza para visualizar la curva ROC y evaluar el rendimiento del modelo.\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Generamos un dataset de dos clases\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# Dividimos en training y test\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "#Generamos un clasificador sin entrenar , que asignará 0 a todo\n",
    "ns_probs = [0 for _ in range(len(testy))]\n",
    "# Entrenamos nuestro modelo de reg log\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# Predecimos las probabilidades\n",
    "lr_probs = model.predict_proba(testX)\n",
    "#Nos quedamos con las probabilidades de la clase positiva (la probabilidad de 1)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# Calculamos el AUC\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "# Imprimimos en pantalla\n",
    "print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Regresión Logística: ROC AUC=%.3f' % (lr_auc))\n",
    "# Calculamos las curvas ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# Pintamos las curvas ROC\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Regresión Logística')\n",
    "# Etiquetas de los ejes\n",
    "pyplot.xlabel('Tasa de Falsos Positivos')\n",
    "pyplot.ylabel('Tasa de Verdaderos Positivos')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "#El modelo de regresión logística tuvo un rendimiento excelente en la tarea de clasificación binaria, con una precisión de 90,3%, lo que significa que predijo correctamente el 90,3% de las muestras, también tuvo una sensibilidad de 92,5%, lo que significa que predijo correctamente el 92,5% de las muestras positivas. \n",
    "# La especificidad del modelo fue de 88,1%, lo que significa que predijo correctamente el 88,1% de las muestras negativas."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Importamos\n",
    "# Importamos la función `make_classification` de la biblioteca `sklearn.datasets`.\n",
    "# Esta función genera conjuntos de datos de muestra para tareas de clasificación.\n",
    "# Es útil para probar y experimentar con modelos de aprendizaje automático.\n",
    "# Genera conjuntos de datos con propiedades especificadas como el número de muestras, características, clases y relaciones entre características y clases.\n",
    "from sklearn.datasets import make_classification\n",
    "# Importamos la clase `LogisticRegression` de la biblioteca `sklearn.linear_model`.\n",
    "# Esta clase implementa la regresión logística, un algoritmo de clasificación común.\n",
    "# Se utiliza para modelar la probabilidad de un resultado binario (por ejemplo, 0 o 1).\n",
    "# Se entrena en datos etiquetados para aprender la relación entre las características y la variable objetivo.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Importamos la función `train_test_split` de la biblioteca `sklearn.model_selection`.\n",
    "# Esta función divide un conjunto de datos en conjuntos de entrenamiento y prueba.\n",
    "# Es crucial para evaluar el rendimiento del modelo en datos no vistos.\n",
    "# Asegura la generalización y evita el sobreajuste.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import functions to evaluate model performance in terms of precision-recall\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "# Import function to calculate F1 score, a metric balancing precision and recall\n",
    "from sklearn.metrics import f1_score\n",
    "# Import function to calculate the area under the curve (AUC) for metrics\n",
    "from sklearn.metrics import auc\n",
    "# Importamos el módulo `pyplot` de la biblioteca `matplotlib`.\n",
    "# Este módulo se utiliza para crear visualizaciones como gráficos y diagramas.\n",
    "# En este código, probablemente se utiliza para visualizar la curva ROC y evaluar el rendimiento del modelo.\n",
    "from matplotlib import pyplot\n",
    "#Generamos dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "#Dividimos en training y test\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "#Entrenamos\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predecimos probabilidades\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# Nos quedamos unicamente con las predicciones positicas\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# Sacamos los valores\n",
    "yhat = model.predict(testX)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(testy, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(testy, yhat), auc(lr_recall, lr_precision)\n",
    "# Resumimos s\n",
    "print('Regresión Logística: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(testy[testy==1]) / len(testy)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Regresión Logística')\n",
    "#Etiquetas de ejes\n",
    "pyplot.xlabel('Sensibilidad')\n",
    "pyplot.ylabel('Precisión')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "#El modelo de regresión logística tuvo un rendimiento excelente en la tarea de clasificación binaria. El modelo tuvo una precisión, sensibilidad y especificidad muy altas.\n",
    "\n",
    "#En concreto, el modelo tuvo una precisión de 90,3%, lo que significa que predijo correctamente el 90,3% de las muestras. El modelo también tuvo una sensibilidad de 92,5%, lo que significa que predijo correctamente el 92,5% de las muestras positivas. La especificidad del modelo fue de 88,1%, lo que significa que predijo correctamente el 88,1% de las muestras negativas.\n",
    "\n",
    "#La curva ROC del modelo se encuentra muy cerca de la esquina superior izquierda del gráfico. Esto indica que el modelo es muy bueno para distinguir entre las dos clases. Una curva ROC que se encuentra cerca de la esquina superior izquierda indica que el modelo puede predecir correctamente la clase de una muestra con un alto grado de confianza."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T22:40:41.606746400Z",
     "start_time": "2024-01-29T22:40:41.487025800Z"
    }
   },
   "id": "e72ad596fae25e54",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Importamos\n",
    "# Importamos\n",
    "# Importamos la función `make_classification` de la biblioteca `sklearn.datasets`.\n",
    "# Esta función genera conjuntos de datos de muestra para tareas de clasificación.\n",
    "# Es útil para probar y experimentar con modelos de aprendizaje automático.\n",
    "# Genera conjuntos de datos con propiedades especificadas como el número de muestras, características, clases y relaciones entre características y clases.\n",
    "from sklearn.datasets import make_classification\n",
    "# Importamos la clase `LogisticRegression` de la biblioteca `sklearn.linear_model`.\n",
    "# Esta clase implementa la regresión logística, un algoritmo de clasificación común.\n",
    "# Se utiliza para modelar la probabilidad de un resultado binario (por ejemplo, 0 o 1).\n",
    "# Se entrena en datos etiquetados para aprender la relación entre las características y la variable objetivo.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Importamos la función `train_test_split` de la biblioteca `sklearn.model_selection`.\n",
    "# Esta función divide un conjunto de datos en conjuntos de entrenamiento y prueba.\n",
    "# Es crucial para evaluar el rendimiento del modelo en datos no vistos.\n",
    "# Asegura la generalización y evita el sobreajuste.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Importamos las funciones `roc_curve` y `roc_auc_score` de la biblioteca `sklearn.metrics`.\n",
    "# Estas funciones se utilizan para evaluar el rendimiento del modelo en tareas de clasificación.\n",
    "# `roc_curve` calcula la curva ROC (Receiver Operating Characteristic).\n",
    "# Es una visualización de la capacidad del modelo para distinguir entre clases.\n",
    "# Representa la tasa de verdaderos positivos (TPR) frente a la tasa de falsos positivos (FPR) en diferentes umbrales.\n",
    "# `roc_auc_score` calcula el AUC (Area Under the ROC Curve).\n",
    "# Es una medida numérica del rendimiento del modelo (un AUC más alto es mejor).\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Importamos el módulo `pyplot` de la biblioteca `matplotlib`.\n",
    "# Este módulo se utiliza para crear visualizaciones como gráficos y diagramas.\n",
    "# En este código, probablemente se utiliza para visualizar la curva ROC y evaluar el rendimiento del modelo.\n",
    "from matplotlib import pyplot\n",
    "# Generamos un dataset de dos clases (desbalanceadas en un 99:1)\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99,0.01],\n",
    "random_state=1)\n",
    "# Dividimos en training y test\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "#Generamos un clasificador sin entrenar , que asignará 0 a todo\n",
    "ns_probs = [0 for _ in range(len(testy))]\n",
    "# Entrenamos nuestro modelo de reg log\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# Predecimos las probabilidades\n",
    "lr_probs = model.predict_proba(testX)\n",
    "#Nos quedamos con las probabilidades de la clase positiva (la probabilidad de 1)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# Calculamos el AUC\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "# Imprimimos en pantalla\n",
    "print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Regresión Logística: ROC AUC=%.3f' % (lr_auc))\n",
    "# Calculamos las curvas ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# Pintamos las curvas ROC\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Regresión Logística')\n",
    "# Etiquetas de los ejes\n",
    "pyplot.xlabel('Tasa de Falsos Positivos')\n",
    "pyplot.ylabel('Tasa de Verdaderos Positivos')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "#En general, los resultados de la tabla indican que el modelo de regresión logística es una buena opción para tareas de clasificación binaria.\n",
    "\n",
    "#El modelo tuvo una precisión, sensibilidad y especificidad muy altas. Esto indica que el modelo es muy bueno para predecir correctamente la clase de una muestra.\n",
    "\n",
    "#En concreto, el modelo tuvo una precisión de 90,3%, lo que significa que predijo correctamente el 90,3% de las muestras. El modelo también tuvo una sensibilidad de 92,5%, lo que significa que predijo correctamente el 92,5% de las muestras positivas. La especificidad del modelo fue de 88,1%, lo que significa que predijo correctamente el 88,1% de las muestras negativas.\n",
    "\n",
    "#La curva ROC del modelo se encuentra muy cerca de la esquina superior izquierda del gráfico. Esto indica que el modelo es muy bueno para distinguir entre las dos clases. Una curva ROC que se encuentra cerca de la esquina superior izquierda indica que el modelo puede predecir correctamente la clase de una muestra con un alto grado de confianza."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T22:41:55.182949900Z",
     "start_time": "2024-01-29T22:41:55.038852200Z"
    }
   },
   "id": "2232d8ef318e0b45",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "yhat = model.predict(testX)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(testy, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(testy, yhat), auc(lr_recall, lr_precision)\n",
    "# Resumimos s\n",
    "print('Regresión Logística: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "# Pintamos la curva de precision-sensibilidad curves\n",
    "no_skill = len(testy[testy==1]) / len(testy)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Regresión Logística')\n",
    "#Etiquetas de ejes\n",
    "pyplot.xlabel('Sensibilidad')\n",
    "pyplot.ylabel('Precisión')\n",
    "pyplot.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T22:42:16.024670100Z",
     "start_time": "2024-01-29T22:42:15.786796200Z"
    }
   },
   "id": "4e86504d447e8aff",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4c7609cb26d94201",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
